* Terms
** Orchestrator
A system that deploys and manages applications, it can deploy applications and dynamically respond to changes for example, kubernetes can:
 - Deploy your application
 - Scale it up and  down dynamically based on demand
 - Self healing
 - Zero-downtime updates & rollbacks
** Cloud-native app
Fulfills criteria such as:
 - auto-scaling
 - self-healing
 - rolling-updates
 - rollbacks 
 - etc
** Container runtime interface
Abstraction layer that standardizes container interface and allows using different containers
** Cluster
The worker nodes and control plane nodes running the application(s)
** Control Plane
 - API for interacting with the cluster
 - Scheduler for assigning work
 - Persistent store for recording the state of the cluster and apps
** Nodes
 - The machines on which the user applications run.
** Orchestrator
   A system which manages and deploys applications
** Manifest
   A Yaml configuration file describing the desired state of an application.
** Pod
   - A wrapper for one or more containers allowing them to be run on a kubernetes cluster.
   - Pods are *the* atomic unit in kubernetes, when scaling an app you must add more pods rather than more containers.
   - A single pod can only be scheduled to a single node.
   - Pods are immutable, any changes require the destruction and replacement of the existing pod.
   - Pods are said to be unreliable, they will not persist.

** Deployment
 - A type of controller used for running pods
 - Offers scalability, self-healing, and rolling updates for stateless apps
 - Defined in manifests
 - Enacted by posting to the API server as the _desired state_ of the application.
 - User labels and selectors to find Pods they own
** Declarative Model
  1. Declare the desired state of an application microservice in a manifest
  2. post to API server
  3. K8s stores it in the cluster store as the /desired state/
  4. K8s implements the desired state on the cluster
  5. A controller ensures the /observed state/ matches the /desired state/
** Desired state
   - What an application should look like, as defined by the manifest
   - Includes images to use, replica numbers, network ports and how to update.
** Services
  - Provide stable and reliable networking for a set of pods
  - Front-end consisting of a stable DNS-name, ip address and port.
  - Back-end load-balancing traffic across set of pods.
  - Updates routing as pods are created and destroyed automatically.
  - Determine Pods to send traffic to using lables and selectors
  - For a Service to route to a Pod it must have every label the Service is selecting on
  - *Selector* is the list of label the service uses to find destination pods
  - *Port* is the port the service listens on inside the cluster
  - *TargetPort* is the port the application listens on
  - *NodePort* is the cluster-wide port which can be used for external access
  - *Endpoint* is the list of Pod IPs whose labels are currently matching the selector
*** Features
    - Stable IP address
    - Stable DNS name
    - Stable Port
*** Types
**** ClusterIP
     - The default type
     - Stable Virtual IP only accessible from inside the cluster
**** NodePort
     - An extension of a ClusterIP, enables external access via a dedicated port on every cluster node.
     - NodePorts only work with ports 30000-32767
**** LoadBalancer
     - Integrates with internet facing load balancers on your cloud platform providing high-performance, high-availability public IP or DNS.
     - Only work on clouds that support them.
** Endpoints
Automatically created with every service, an Endpoints object is used to store a dynamic list of healthy Pods matching the Service's label selector
** Ingress
   - Allows exposing multiple Services through a single cloud load-balancer
   - Creates a LoadBalancer Service on 80 or 443 and uses both host-based and path-based routing to send traffic to the correct backend service
   - The traffic routing rules are defined by the object spec
*** Classes
    These are user-defined ingress types which can be used to created Ingress objects with a specific base ingress type and collection of metadata
** kube-proxy
   - Captures ClusterIP traffic and redirects it to the IP of Pods matching the Services label selector
   - Pod-based Kubernetes-native app.
   - Implements controller watching API server for new Services and Endpoints objects.
   - Creates local IPVS rules telling the node to intercept Service ClusterIP traffic and forward it to Pod IPs 
** Service Discovery
Two major components:
*** Registration
    - Application posts its connection details to a /service registry/ so other apps can find it.
    - Service registry is k8s internal DNS
    - All K8s services automatically register their details with DNS
    - Every pod in the cluster know where to find the cluster DNS (it is said to be /well-known/)
    - Implemented in the kube-system namespace as a set of pods managed by a deployment called coredns and fronted by a service called kube-dns
    - Internally based on CoreDNS and run as a /kubernetes-native/ application
    - The name of an app used in the internal dns is taken from the metadata name attribute
**** Registration Flow
     1. Service manifest posted to API server
     2. Service allocated Stable, internal ClusterIP
     3. Endpoints created to hold a list of healthy pods matching Services selector
     4. Pod network configured to handle traffic arriving at ClusterIP
     5. Service Name and IP registered with cluster DNS
*** Discovery
    - Kubernetes populates each containers /etc/resolv.conf with the cluster DNS service and any search domains to be appended to unqualified names
    - Every cluster has an address space partitioned by Namespaces
    - The cluster domain is usually `cluster.local` and objects have unique names within it e.g. a service called ent would have a FQDN of ent.default.svc.cluster.local
    - The domain format is <object-name>.<namespace>.svc.cluster.local
    - Object can use just their short names to connect to namespace local Services but require FQDNs to connect across namespaces
**** Inter-app communication
     1. Know the name of the remote apps service
     2. Name Resolution
     3. Network routing
** Kubernetes-native application
   An application that is aware it's running on K8s and can talk to the k8s API
* Technologies 
** containerd
A stripped down version of the docker runtime with just the features required by kubernetes. The sandard docker runtime was deprecated for use with Kubernetes in 1.20
** Control Plane
The central hub of the cluster consisting of one or more control plane nodes
*** API Server
  - The centralised mediator for all communiation between all components.
  - Exposes a rest API that you can POST YAML conf files to.
*** Cluster Store
  - The only stateful part of the control plane
  - Persists the entire configuration and state of the cluster
  - Currently based on etcd
*** Controller Manager
  - Spawns, manages and monitors all independent controllers
*** Controller
  - Monitors cluster components and responds to events
  - Individually responsible for a small subset of cluster intelligence
**** Controller logic:
  1. Obtain desired state
  2. Observe current state
  3. Determine differences
  4. Reconcile differences
*** Scheduler
  - Watches API server for new work tasks and assigns them to healthy worker nodes.
  - The scheduler uses a ranking algorithm to choose the most appropriate node to run the task on.
  - A Task is normally a pod/container.
*** Cloud Controller Manager
    Facilitates integrations with cloud services such as instances, load-balancers and storage.
** Worker Nodes
*** Tasks
  1. Watch the API server for new work assignments
  2. Execute work assignments
  3. Report back to the control plane (via the API server)
*** Components
**** Kubelet
    - The main kubernetes agent (often node and kubelet are used interchangeably)
    - Adding node to a cluster installs the kubelet which registers it and the nodes cpu, memory and storages in the nodes cluster pool.
    - The three tasks above are executed by the kubelet.
**** Container Runtime
     - Performs container-related tasks e.g. pulling images, starting/stopping containers, etc.
**** Kube-proxy
     - Manages local cluster-networking
     - Ensures each node gets its own ip address and implements local rules to handle routing and load balancing of traffic on the pod network.
** Kubernetes DNS
Internal DNS service to enable service discovery.
  - The dns service has a static ip hard-coded into every pod on the cluster, ensuring every container and Pod can locate it and use it for discovery.
  - Cluster DNS is based on the CoreDNS project.
** Pods
 - Pods are almost always deployed via /controllers/
*** Pod Theory
    
    - Pods are the atomic scheduling unit in kubernetes
    - Pods serve as a wrapper around containers that kubernetes is able to recognise and interact with
    - Pods are mortal, they must be totally recreated when destroyed
    - State and data must always be stored outside pod
    - A pod is just an execution environment shared by one or more containers, essentially just a container containing containers
    - Each pod gets a single ip shared by all the containers inside
    - Each pod sits on an internal kubernetes network called the /pod network/
    - Pod deployment is atomic, only once fully deployed will it start servicing requests
    - Pods can be either short or long lived
    - Pods are immutable objects. This means you can't modify them after they're deployed.
    - When a failure occurs or an update is required the pod is simply discarded and replaced
      
**** Features
***** Labels
Let you group pods and associate them with other objects
***** Annotations
Add experimental features and integrations with third party tools
***** Probes
- test the status and health of pods
- Enable advanced scheduling
- updates
***** Affinity & anti-affinity
control where pods run
***** Termination control
Gracefully terminate pods and their contained applications

*** Manifests fields

**** spec.initContainers
This block defines one or more containers that k8s guarantees will run and complete before main app container starts

** Controllers
 - Controllers enable features such as self-healing, scaling, updates & rollbacks
 - Every controller has a PodTemplate which defines the pods it deploys & manages
** Namespaces
   - Divide a cluster into multiple virtual clusters
   - Allow the application of quotas and policies to groups of objects
   - Objects are said to be /namespaced/ (pods, services and deployments)
   - Unless a namespace is explicitly defined for the target object it will be deployed to the default namespace
** Deployments
   - Deploymnets rely heavily on objects called ReplicaSets
   - Each Deployment object manages a single Pod template, however a single deployment _can_ manage multiple replicas of the same Pod.
*** Deployment Theory
     - Deployment is a /controller/ designed for stateless apps.
**** Deployment spec
YAML object describing the desired state of a stateless app
**** Deployment controller
This implements and manages the spec, it is highly-available and runs in the background constantly monitoring the app and reconciling the observed state with the desired state.

*** Rolling Updates
    - zero-downtime rolling updates are a key feature of deployments, however they require both loose coupling via aAPIs and backwards _and_ forwards compatibility
    - All microservices in an app should be decoupled and only communicate through well-defined APIs
    - Once a rollout is complete, the original ReplicaSet is wound down and no longer manages any pods, however it's configuration still exists on the cluster in case of a rollback.
      
*** spec
    - No. of Pod replicas
    - Images to use for Pods containers
    - Ports to expose
    - How to perform rolling updates

** Service
   - Allow access of apps from outside the cluster

** ReplicaSets
 - These represent an intermediate level between Deployments and Pods
 - Replaces failed pods (self healing)
 - Adds or removes pods depending on increased/decreased load (scaling)
** Storage
   - All types of storage are referred to as volumes when exposed on kubernetes
   - Storage plugins are called provisioners in kubernetes
     
*** RetainPolicy
    Tells K8s how to deal with a PV released by its PVC
**** Delete
     Removes not only the PV but also the associated storage resource on the external storage system
**** Retain
     Keep both the PV and the underlying storage resource

*** Container Storage Interface (CSI)
    - Standards-based storage interface providing uniform kubernetes access.

*** Persistent Storage Subsystem
**** PersistentVolumes (PV)
     - Mapped to external storage assets
**** PersistentVolumeClaims (PVC)
     - Tickets authorising pods to use PVs
**** StorageClasses (SC)
     - Allow creation of PVs in response to PVCs
     - Define different classes/tiers of storage e.g. fast-storage and slow-storage
     - the `provisioner` field tells kubernetes which plugin to use
     - Immutable
     - metadata.name needs to be meaningful
     - Plugin-specific values are given in the parameters block.
     - Each storage class relates to only a single type of storage on a single backend
***** Workflow
      1. Get a storage backend
      2. Create cluster
      3. Install & configure the CSI storage plugin
      4. Create one or more StorageClasses
      5. Deploy Pods and PVCs referencing the above StorageClasses
*** Access Modes
**** ReadWriteOnce (RWO)
     Defines a PV that can only be bound as RW by a single PVC.
**** ReadWriteMany (RWM)
     - Bindable as RW by multiple PVCs.
     - Usually only supported by file and object storage such as NFS.
**** ReadOnlyMany (ROM)
** ConfigMap
   - Used to store non-sensitive config information
   - Structured as a dictionary of key/value pairs separated by colons entries
   - values can range from single digits up to entire configuration files
   - Data stored in configmaps can be injected into containers at runtime
   - Environment variables cannot be updated dynamically
   - Using volumes allows configmap changes to be reflected in running containers
     
*** Examples:
    - Environment variables
    - Config files
    - Hostnames
    - Service ports
    - Accounts names
*** Injection methods
    - Environment variables
    - arguments to container startup commands
    - files in a volume
** Secrets
   - Configmaps but for sensitive data
   - Secrets are not encrypted but instead obscured by being re-encoded as base-64
   - Limited to 1MiB
   - Every Pod gets a secret mounted as volume which is used tto authenticate with the api server
   - Secret volumes are automatically mounted as read-only
*** Workflow
    1. Secret created and persisted to cluster store
    2. Pod using secret scheduled to cluster node
    3. secret transferred un-encrypted to node
    4. Kubelet on node starts pod
    5. Secret mounted into container via in-memory tempfs filesystem and decoded from base64
    6. Application consumes secret
    7. When Pod is deleted, secrete deleted from node
** StatefulSets
   - Controller similar to deployments
   - Predictable and persistent Pod names, DNS hostnames and volume bindings form the 'state' of a Pod which is persisted across failures, scalinng and other scheduling operations.
* Config
** kubeconfig file
 - Usually found in '~/.kube/config'
   Contains definitions for 3 objects
*** Clusters
A list of all the clusters that kubectl knows about
*** Users
A list of users and their credentials
*** Contexts
Groups of clusters and users under a friendly name.

* Requirements
There are three features an app must have to be run on a cluster:
  1. Packaged as a container
  2. Wrapped in a pod
  3. Deployed via a declarative manifest file
* Deployment process 
  1. Create Manifest
  2. Post to API server (using kubectl)
  3. K8s sends it to the identified controller (usually the /deployments controller/)
  4. K8s records the config in the cluster store as part of the desired state.
  5. Any required work tasks are scheduled to cluster work nodes.
  6. Controllers run as background reconciliation loops monitoring the cluster state.
* Useful Commands
** Examining pods
kubectl get pods
kubectl describe pods
kubectl logs // get the logs from a specific pod
** Running commands in pods
kubectl exec <pod> -- <command> // basically like docker exec, not the dual hyphen between pod and command

If running a shell make sure you add the -it flags to make the session interactive and redirect STDIN and STDOUT to your shell respectively.
** Pause a rollout in progress
kubectl rollout pause deploy <deployment-name>
*** And restart it 
kubectl rollout resume deploy <deployment-name>
** Editing existing configmaps
   The below command opens the contents of the specified configmap using vi
   #+begin_src sh
   kubectl edit cm <configmap>
   #+end_src

* Hierarchy
 - Application - your app
   - Containers - packages application and dependencies
     - Pods - Enable kubernetes to run containers and co-scheduling etc.
       - ReplicaSets - Manage Pods & enable self healing and scaling
	 - Deployments - Manage ReplicaSets and add rollouts and rollbacks

* Examples
** kubeconfig file
  - A single cluster called shield, as single user called charlie, and a single context called director.
  - The director context combines the charlie user and the shield cluster and is also set as the default context
    #+begin_src yaml
      apiVersion: v1
      kind: Config
      clusters:
	- cluster:
	    certificate-autority: /home/zenobia/.minikube/ca.crt
	    server: https://192.168.1.77:8443
	    name: shield
      users:
	- name: charlie
	  user:
	    client-certificate: /home/zenobia/.minikube/client.crt
	    client-key: /home/zenobia/.minikube/client.key
      contexts:
	- context:
	    cluster: shield
	    user: charlie
	  name: director
      current-context: director
    #+end_src
** pod
#+begin_src yaml
apiVersion: v1 # The schema version to use when creating the object
kind: Pod # This tells k8s the type of object being defined, in this case, a pod.
metadata:
  name: hello-pod
  labels:
    zone: prod
    version: v1
spec: # This section defines the containers the pod will run and is called the pod template
  containers:
  - name: hello-ctr
    image: nigelpoulton/k8sbook:latest
    ports:
    - containerPort: 8080
#+end_src
